{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is named SF_taxi_data.csv, and contains San Francisco Taxi data from 9/1/2012 to 9/17/2012. The\n",
    "dataset consists of 50,000 taxi trips taken in the Bay Area during that time period. For each trip you are given\n",
    "the departure time, arrival time, passenger fare, departure lat/lon coordinates, arrival lat/lon coordinates,\n",
    "departure taz (Traffic Analysis Zone), arrival taz, and the distance between origin and destination in miles.\n",
    "\n",
    "Data might have outliers and errors. To make sure that you have removed all the outliers, do the following:\n",
    "\n",
    "    • Get trips where the number of passengers is only 1, and remove fares less than $3.5, since base fare\n",
    "    = $3.5, these are likely to be errors. Do the rest of analysis on this filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>id</th> <th>departure time</th> <th>arrival time</th> <th>fare ($)</th> <th>num</th> <th>dep lon</th> <th>dep lat</th> <th>arr lon</th> <th>arr lat</th> <th>deptaz</th> <th>arrtaz</th> <th>dist (miles)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0   </td> <td>9/1/12 0:11   </td> <td>9/1/12 0:20 </td> <td>13.2    </td> <td>1   </td> <td>-122.414</td> <td>37.8027</td> <td>-122.421</td> <td>37.7854</td> <td>38    </td> <td>30    </td> <td>1.98084     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>9/1/12 0:23   </td> <td>9/1/12 0:31 </td> <td>10.65   </td> <td>1   </td> <td>-122.42 </td> <td>37.7861</td> <td>-122.435</td> <td>37.7622</td> <td>30    </td> <td>94    </td> <td>2.40224     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2   </td> <td>9/1/12 0:45   </td> <td>9/1/12 0:49 </td> <td>9       </td> <td>1   </td> <td>-122.415</td> <td>37.7747</td> <td>-122.408</td> <td>37.7826</td> <td>10    </td> <td>11    </td> <td>0.479348    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>3   </td> <td>9/1/12 0:41   </td> <td>9/1/12 0:54 </td> <td>13.95   </td> <td>2   </td> <td>-122.419</td> <td>37.8066</td> <td>-122.415</td> <td>37.7781</td> <td>40    </td> <td>10    </td> <td>2.12241     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>4   </td> <td>9/1/12 1:09   </td> <td>9/1/12 1:13 </td> <td>7.35    </td> <td>1   </td> <td>-122.43 </td> <td>37.7978</td> <td>-122.418</td> <td>37.789 </td> <td>45    </td> <td>32    </td> <td>1.03807     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>5   </td> <td>9/1/12 1:40   </td> <td>9/1/12 1:52 </td> <td>11.75   </td> <td>1   </td> <td>-122.433</td> <td>37.7841</td> <td>-122.411</td> <td>37.787 </td> <td>77    </td> <td>7     </td> <td>0.960851    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>6   </td> <td>9/1/12 2:49   </td> <td>9/1/12 2:51 </td> <td>5.15    </td> <td>1   </td> <td>-122.409</td> <td>37.7856</td> <td>-122.412</td> <td>37.791 </td> <td>7     </td> <td>29    </td> <td>0.414315    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>7   </td> <td>9/1/12 3:29   </td> <td>9/1/12 3:47 </td> <td>43.65   </td> <td>1   </td> <td>-122.403</td> <td>37.7927</td> <td>-122.386</td> <td>37.6181</td> <td>2     </td> <td>239   </td> <td>14.5105     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>8   </td> <td>9/1/12 0:33   </td> <td>9/1/12 0:57 </td> <td>46.75   </td> <td>1   </td> <td>-122.387</td> <td>37.6174</td> <td>-122.407</td> <td>37.7889</td> <td>239   </td> <td>5     </td> <td>14.2747     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>9   </td> <td>9/1/12 4:39   </td> <td>9/1/12 4:43 </td> <td>6.25    </td> <td>1   </td> <td>-122.422</td> <td>37.7977</td> <td>-122.418</td> <td>37.789 </td> <td>34    </td> <td>31    </td> <td>0.685312    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (49991 rows omitted)</p"
      ],
      "text/plain": [
       "id   | departure time | arrival time | fare ($) | num  | dep lon  | dep lat | arr lon  | arr lat | deptaz | arrtaz | dist (miles)\n",
       "0    | 9/1/12 0:11    | 9/1/12 0:20  | 13.2     | 1    | -122.414 | 37.8027 | -122.421 | 37.7854 | 38     | 30     | 1.98084\n",
       "1    | 9/1/12 0:23    | 9/1/12 0:31  | 10.65    | 1    | -122.42  | 37.7861 | -122.435 | 37.7622 | 30     | 94     | 2.40224\n",
       "2    | 9/1/12 0:45    | 9/1/12 0:49  | 9        | 1    | -122.415 | 37.7747 | -122.408 | 37.7826 | 10     | 11     | 0.479348\n",
       "3    | 9/1/12 0:41    | 9/1/12 0:54  | 13.95    | 2    | -122.419 | 37.8066 | -122.415 | 37.7781 | 40     | 10     | 2.12241\n",
       "4    | 9/1/12 1:09    | 9/1/12 1:13  | 7.35     | 1    | -122.43  | 37.7978 | -122.418 | 37.789  | 45     | 32     | 1.03807\n",
       "5    | 9/1/12 1:40    | 9/1/12 1:52  | 11.75    | 1    | -122.433 | 37.7841 | -122.411 | 37.787  | 77     | 7      | 0.960851\n",
       "6    | 9/1/12 2:49    | 9/1/12 2:51  | 5.15     | 1    | -122.409 | 37.7856 | -122.412 | 37.791  | 7      | 29     | 0.414315\n",
       "7    | 9/1/12 3:29    | 9/1/12 3:47  | 43.65    | 1    | -122.403 | 37.7927 | -122.386 | 37.6181 | 2      | 239    | 14.5105\n",
       "8    | 9/1/12 0:33    | 9/1/12 0:57  | 46.75    | 1    | -122.387 | 37.6174 | -122.407 | 37.7889 | 239    | 5      | 14.2747\n",
       "9    | 9/1/12 4:39    | 9/1/12 4:43  | 6.25     | 1    | -122.422 | 37.7977 | -122.418 | 37.789  | 34     | 31     | 0.685312\n",
       "... (49991 rows omitted)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi = Table().read_table(\"SF_taxi_data.csv\")\n",
    "taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Analysis 1. SFMTA fare calculation table states that the fare for a trip of x miles will be at least\n",
    "3.5 + 0.55 × (5x − 1). Explore how this compares to the actual relationship between fares and distance that\n",
    "you can find using regression methods that you have learned in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis 2. Turns out the TAZ that contains SFO (San Francisco International Airport) is the TAZ that\n",
    "generates the most trips. find the most popular “deptaz” and save the taz id as sfo_taz. Then split the\n",
    "dataset into two groups of trips that originated or ended at SFO, and the rest of the trips. What can you say\n",
    "about these two groups of data? How different they are? (your answers need to be quantitative, based on\n",
    "some measures or metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "Analysis 3. In most trips, the actual fare was way higher than the base one (the equation given in analysis\n",
    "1). The reason for the extra fare paid by pax is traffic delays (and also drivers taking longer trips than\n",
    "necessary, sometimes due to congestion). Let’s see if this extra surcharge is related to the length and duration\n",
    "of the trip. This will help us predict it before a trip started. Fit a linear regression of travel distance vs. extra\n",
    "cost (the cost above the base fare) on the data from Day 1 to Day 10 of September, and see how the fitted\n",
    "line predicts the fares for data from Day 11 to Day 17? What is the error in prediction?\n",
    "\n",
    "Analysis 4. Both length and duration of a trip seem to have an association with extra fares. Longer trips\n",
    "are more expensive. Do the same analysis in (3), but for travel duration vs. extra cost, and identify whether\n",
    "trip length or trip duration seem to be a better predictor of the extra travel fare?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression vs. k-nearest neighbor\n",
    "\n",
    "Analysis 5. Take the data of fares and distances from day 1 to day 10 of September as training data, and\n",
    "data from day 11 to day 17 as testing data. Apply both linear regression and k-nearest neighbor (with\n",
    "k = {1, 5, 10}) to identify the fares in the testing data given the distances and compare the results. Which\n",
    "method is better and why? What is the difference between performance of k-NN with different values of k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
